{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b154e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35b73616f3f49e0b0c6abf7827b6cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5335b596867d45b6b5f2612e013a6afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08a73e4bf574e30a7be79cde5cf5170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cosmos-Reason2-8B locations: 100%|██████████| 1/1 [00:07<00:00,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/rishabh.mondal/Brick-Kilns-project/ijcai_2025_kilns/temporal-analysis/cosmos_reason2_8b_kiln_change_results_delhi_all_loc_bbox_testing.csv\n",
      "status\n",
      "ok    1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# =========================\n",
    "# GPU + CPU LIMITS (set before torch/transformers)\n",
    "# =========================\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"   # physical GPU 2,3 only\n",
    "N_THREADS = 16\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(N_THREADS)\n",
    "os.environ[\"MKL_NUM_THREADS\"] = str(N_THREADS)\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = str(N_THREADS)\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = str(N_THREADS)\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = str(N_THREADS)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from transformers import Qwen3VLForConditionalGeneration, AutoProcessor\n",
    "import tqdm\n",
    "\n",
    "torch.set_num_threads(N_THREADS)\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "YEARS = [2014, 2016, 2018, 2020, 2022, 2024]\n",
    "YEARS_STR = \", \".join(str(y) for y in YEARS)\n",
    "\n",
    "BASE_DIR = Path(\"/home/rishabh.mondal/Brick-Kilns-project/ijcai_2025_kilns/temporal-analysis/data\")\n",
    "FOLDER_TPL = \"delhi_airshed_y_{y}_z_17_buf_25m\"\n",
    "BBOX_LABELS_DIR = Path(\n",
    "    \"/home/rishabh.mondal/Brick-Kilns-project/ijcai_2025_kilns/temporal-analysis/data/\"\n",
    "    \"delhi_airshed_y_2025_z_17_buf_25m_symlink/labels\"\n",
    ")\n",
    "BBOX_YEAR = 2025\n",
    "BBOX_CSV = Path(\n",
    "    \"/home/rishabh.mondal/Brick-Kilns-project/ijcai_2025_kilns/temporal-analysis/\"\n",
    "    \"cosmos_reason2_bbox_pixels_2025.csv\"\n",
    ")\n",
    "\n",
    "MODEL_ID = \"nvidia/Cosmos-Reason2-8B\"\n",
    "OUT_CSV = \"/home/rishabh.mondal/Brick-Kilns-project/ijcai_2025_kilns/temporal-analysis/cosmos_reason2_8b_kiln_change_results_delhi_all_loc_bbox_testing.csv\"\n",
    "\n",
    "MAX_NEW_TOKENS = 4096  # Cosmos needs more tokens for chain-of-thought\n",
    "N_LOCATIONS = 924\n",
    "LIMIT = 1 # set e.g. 10 for testing\n",
    "SAVE_PROMPT_IN_CSV = True\n",
    "TARGET_LOC = None # e.g. \"28.604682_77.471200\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# PROMPT\n",
    "# =========================\n",
    "PROMPT_TEMPLATE = f\"\"\"\n",
    "You are analyzing multi year satellite image chips of the SAME location across years {YEARS_STR}.\n",
    "Pixel bboxes from 2025 YOLO labels, format: [x_min, y_min, x_max, y_max].\n",
    "{{BBOX_LINE}}\n",
    "Use these exact boxes for all years. Do not invent boxes.\n",
    "If the list is [[0, 0, 0, 0]], treat as negative (no bbox).\n",
    "Detect brick kiln like structures and track changes.\n",
    "\n",
    "Return STRICT JSON only. No markdown. No extra text.\n",
    "\n",
    "Definitions:\n",
    "presence: true if kiln like structure is present in the location in any year, false otherwise\n",
    "kiln_present: whether kiln like structure exists in that year\n",
    "kiln_shape: one of [\"circular_oval\",\"oval_round\",\"rectangular_sharp_edge_corners\",\"none\"]\n",
    "kiln_type: one of [\"FCBK\",\"CFCBK\",\"Zigzag\",\"none\"]\n",
    "\n",
    "Infer:\n",
    "presence: true if any year has kiln_present true, otherwise false\n",
    "appearance_year: first year kiln_present becomes true\n",
    "type transition: (FCBK or CFCBK) -> Zigzag\n",
    "shape transition: circular_oval or oval_round -> rectangular_sharp_edge_corners\n",
    "demolished_year: first year after being present where kiln_present becomes false and stays absent thereafter (best effort)\n",
    "negative_sample: true if kiln_present is false for all years\n",
    "\n",
    "Output JSON schema:\n",
    "{{\n",
    "  \"presence\": <true/false>,\n",
    "  \"appearance_year\": <int or 0>,\n",
    "  \"appearance_type\": \"<kiln_type at appearance or 'none'>\",\n",
    "  \"type_transition_year_before\": <int or 0>,\n",
    "  \"type_transition_year_after\": <int or 0>,\n",
    "  \"type_transition_note\": \"<short>\",\n",
    "  \"shape_transition_year_before\": <int or 0>,\n",
    "  \"shape_transition_year_after\": <int or 0>,\n",
    "  \"shape_transition_note\": \"<short>\",\n",
    "  \"demolished\": <true/false>,\n",
    "  \"demolished_year\": <int or 0>,\n",
    "  \"negative_sample\": <true/false>,\n",
    "  \"monitoring_note_one_line\": \"<one line summary of evolution over years>\",\n",
    "  \"confidence\": \"<low|medium|high>\"\n",
    "}}\n",
    "\n",
    "Be conservative. If unsure set type or shape to \"unknown\". If not present set to \"none\".\n",
    "\"\"\"\n",
    "\n",
    "# =========================\n",
    "# Build year maps\n",
    "# =========================\n",
    "def build_year_maps() -> Dict[int, Dict[str, Path]]:\n",
    "    year_maps: Dict[int, Dict[str, Path]] = {}\n",
    "    for y in YEARS:\n",
    "        folder = BASE_DIR / FOLDER_TPL.format(y=y)\n",
    "        if not folder.exists():\n",
    "            raise FileNotFoundError(f\"Missing folder: {folder}\")\n",
    "\n",
    "        mapping: Dict[str, Path] = {}\n",
    "        for f in folder.glob(\"*.png\"):\n",
    "            # expected: 28.208668_77.420208_2014.png\n",
    "            parts = f.stem.split(\"_\")\n",
    "            if len(parts) >= 3:\n",
    "                key = f\"{parts[0]}_{parts[1]}\"\n",
    "                mapping[key] = f\n",
    "        year_maps[y] = mapping\n",
    "    return year_maps\n",
    "\n",
    "def build_locations(n_locations: int) -> List[str]:\n",
    "    year_maps = build_year_maps()\n",
    "    common = set.intersection(*(set(year_maps[y].keys()) for y in YEARS))\n",
    "    common = sorted(list(common))\n",
    "    if len(common) < n_locations:\n",
    "        raise ValueError(f\"Need {n_locations} common locations, found {len(common)}\")\n",
    "    return common[:n_locations]\n",
    "\n",
    "def load_images_for_loc(loc: str) -> List[Image.Image]:\n",
    "    year_maps = build_year_maps()\n",
    "    imgs: List[Image.Image] = []\n",
    "    for y in YEARS:\n",
    "        p = year_maps[y][loc]\n",
    "        imgs.append(Image.open(p).convert(\"RGB\"))\n",
    "    return imgs\n",
    "\n",
    "def load_bboxes_for_loc(loc: str) -> List[List[float]]:\n",
    "    label_path = BBOX_LABELS_DIR / f\"{loc}_{BBOX_YEAR}.txt\"\n",
    "    if not label_path.exists():\n",
    "        return []\n",
    "    raw = label_path.read_text().strip()\n",
    "    if not raw:\n",
    "        return []\n",
    "    bboxes: List[List[float]] = []\n",
    "    for line in raw.splitlines():\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) < 4:\n",
    "            continue\n",
    "        # YOLO format: class x_center y_center width height (normalized)\n",
    "        try:\n",
    "            if len(parts) == 4:\n",
    "                coords = parts[0:4]\n",
    "            else:\n",
    "                coords = parts[1:5]\n",
    "            x_c, y_c, w, h = (float(coords[0]), float(coords[1]), float(coords[2]), float(coords[3]))\n",
    "        except ValueError:\n",
    "            continue\n",
    "        bboxes.append([x_c, y_c, w, h])\n",
    "    return bboxes\n",
    "\n",
    "def yolo_to_pixel_bbox(\n",
    "    bboxes: List[List[float]],\n",
    "    img_w: int,\n",
    "    img_h: int,\n",
    ") -> List[List[float]]:\n",
    "    pix: List[List[float]] = []\n",
    "    for x_c, y_c, w, h in bboxes:\n",
    "        x_min = (x_c - (w / 2.0)) * img_w\n",
    "        x_max = (x_c + (w / 2.0)) * img_w\n",
    "        y_min = (y_c - (h / 2.0)) * img_h\n",
    "        y_max = (y_c + (h / 2.0)) * img_h\n",
    "        x_min = max(0.0, min(float(img_w), x_min))\n",
    "        x_max = max(0.0, min(float(img_w), x_max))\n",
    "        y_min = max(0.0, min(float(img_h), y_min))\n",
    "        y_max = max(0.0, min(float(img_h), y_max))\n",
    "        pix.append([x_min, y_min, x_max, y_max])\n",
    "    return pix\n",
    "\n",
    "def build_bbox_csv(locs: List[str]) -> None:\n",
    "    year_maps = build_year_maps()\n",
    "    map_2025 = year_maps[BBOX_YEAR]\n",
    "    rows = []\n",
    "    for loc in locs:\n",
    "        img_path = map_2025.get(loc)\n",
    "        if img_path is None:\n",
    "            continue\n",
    "        with Image.open(img_path) as im:\n",
    "            img_w, img_h = im.size\n",
    "        norm = load_bboxes_for_loc(loc)\n",
    "        pix = yolo_to_pixel_bbox(norm, img_w, img_h)\n",
    "        if not pix:\n",
    "            pix = [[0.0, 0.0, 0.0, 0.0]]\n",
    "        lat, lon = loc.split(\"_\")\n",
    "        rows.append({\n",
    "            \"lat\": float(lat),\n",
    "            \"lon\": float(lon),\n",
    "            \"lat_lon\": loc,\n",
    "            \"bbox_json\": json.dumps(pix, ensure_ascii=False),\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(BBOX_CSV, index=False)\n",
    "\n",
    "def load_bbox_map(locs: List[str]) -> Dict[str, List[List[float]]]:\n",
    "    if not BBOX_CSV.exists():\n",
    "        build_bbox_csv(locs)\n",
    "    df = pd.read_csv(BBOX_CSV)\n",
    "    if \"lat_lon\" not in df.columns or \"bbox_json\" not in df.columns:\n",
    "        build_bbox_csv(locs)\n",
    "        df = pd.read_csv(BBOX_CSV)\n",
    "    missing = set(locs) - set(df[\"lat_lon\"].astype(str).tolist())\n",
    "    if missing:\n",
    "        build_bbox_csv(locs)\n",
    "        df = pd.read_csv(BBOX_CSV)\n",
    "    bbox_map: Dict[str, List[List[float]]] = {}\n",
    "    for _, row in df.iterrows():\n",
    "        loc = str(row[\"lat_lon\"])\n",
    "        raw = row.get(\"bbox_json\", \"[]\")\n",
    "        try:\n",
    "            parsed = json.loads(raw) if isinstance(raw, str) else raw\n",
    "        except Exception:\n",
    "            parsed = [[0.0, 0.0, 0.0, 0.0]]\n",
    "        if not parsed:\n",
    "            parsed = [[0.0, 0.0, 0.0, 0.0]]\n",
    "        bbox_map[loc] = parsed\n",
    "    return bbox_map\n",
    "\n",
    "def format_bboxes_for_prompt(loc: str, bbox_map: Dict[str, List[List[float]]]) -> str:\n",
    "    bboxes = bbox_map.get(loc, [[0.0, 0.0, 0.0, 0.0]])\n",
    "    bbox_strs = []\n",
    "    for bb in bboxes:\n",
    "        if len(bb) != 4:\n",
    "            continue\n",
    "        bbox_strs.append(\"[\" + \", \".join(f\"{v:.2f}\" for v in bb) + \"]\")\n",
    "    if not bbox_strs:\n",
    "        bbox_strs = [\"[0.00, 0.00, 0.00, 0.00]\"]\n",
    "    return \"FOCUS ONLY on the region defined by bounding box: [\" + \", \".join(bbox_strs) + \"]\"\n",
    "\n",
    "# =========================\n",
    "# JSON parse (robust)\n",
    "# =========================\n",
    "def extract_json(text: str):\n",
    "    text = (text or \"\").strip()\n",
    "    # Cosmos may output <think>...</think> reasoning, extract JSON after it\n",
    "    think_match = re.search(r\"</think>\\s*(.+)\", text, flags=re.DOTALL)\n",
    "    if think_match:\n",
    "        text = think_match.group(1).strip()\n",
    "\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        pass\n",
    "    m = re.search(r\"\\{.*\\}\", text, flags=re.DOTALL)\n",
    "    if not m:\n",
    "        return None\n",
    "    cand = m.group(0)\n",
    "    try:\n",
    "        return json.loads(cand)\n",
    "    except Exception:\n",
    "        cand2 = re.sub(r\"\\s+\", \" \", cand).strip()\n",
    "        try:\n",
    "            return json.loads(cand2)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "# =========================\n",
    "# Consistency flags (same logic)\n",
    "# =========================\n",
    "def _as_bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v is None:\n",
    "        return False\n",
    "    if isinstance(v, (int, float)):\n",
    "        return bool(v)\n",
    "    s = str(v).strip().lower()\n",
    "    return s in {\"true\", \"1\", \"yes\", \"present\"}\n",
    "\n",
    "def presence_sequence_from_output(data):\n",
    "    roi = data.get(\"roi_state_by_year\", {}) or {}\n",
    "    seq = []\n",
    "    for y in YEARS:\n",
    "        st = roi.get(str(y), {}) or {}\n",
    "        seq.append(_as_bool(st.get(\"kiln_present\", False)))\n",
    "    return seq\n",
    "\n",
    "def has_inconsistent_presence(seq):\n",
    "    seen_present = False\n",
    "    seen_absent_after_present = False\n",
    "    for v in seq:\n",
    "        if v and not seen_present:\n",
    "            seen_present = True\n",
    "        elif (not v) and seen_present:\n",
    "            seen_absent_after_present = True\n",
    "        elif v and seen_absent_after_present:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def confidence_to_score(conf):\n",
    "    c = str(conf).strip().lower()\n",
    "    if c == \"high\": return 0\n",
    "    if c == \"medium\": return 1\n",
    "    if c == \"low\": return 2\n",
    "    return 1\n",
    "\n",
    "def review_priority(confidence, inconsistent):\n",
    "    return confidence_to_score(confidence) + (2 if inconsistent else 0)\n",
    "\n",
    "def safe_int(x):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    if pd.isna(x):\n",
    "        return 0\n",
    "    return int(x)\n",
    "\n",
    "# =========================\n",
    "# Model load\n",
    "# =========================\n",
    "if torch.cuda.device_count() < 1:\n",
    "    raise RuntimeError(\"No visible CUDA GPUs. Check CUDA_VISIBLE_DEVICES.\")\n",
    "\n",
    "model = Qwen3VLForConditionalGeneration.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"sdpa\",\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(MODEL_ID)\n",
    "\n",
    "# =========================\n",
    "# Run one location with images\n",
    "# =========================\n",
    "def run_one_location(loc: str, bbox_map: Dict[str, List[List[float]]]):\n",
    "    imgs = load_images_for_loc(loc)\n",
    "    bbox_text = format_bboxes_for_prompt(loc, bbox_map)\n",
    "    prompt = PROMPT_TEMPLATE.replace(\"{BBOX_LINE}\", bbox_text)\n",
    "\n",
    "    content = []\n",
    "    for img in imgs:\n",
    "        content.append({\"type\": \"image\", \"image\": img})\n",
    "    content.append({\"type\": \"text\", \"text\": prompt})\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": content}]\n",
    "\n",
    "    inputs = processor.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_dict=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(model.device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        out_ids = model.generate(**inputs, max_new_tokens=MAX_NEW_TOKENS)\n",
    "\n",
    "    trimmed = [o[len(i):] for i, o in zip(inputs[\"input_ids\"], out_ids)]\n",
    "    text = processor.batch_decode(trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "    data = extract_json(text)\n",
    "    return text, data, prompt\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "if TARGET_LOC is not None:\n",
    "    year_maps = build_year_maps()\n",
    "    common = set.intersection(*(set(year_maps[y].keys()) for y in YEARS))\n",
    "    if TARGET_LOC not in common:\n",
    "        raise ValueError(f\"TARGET_LOC not found in common locations: {TARGET_LOC}\")\n",
    "    locs = [TARGET_LOC]\n",
    "else:\n",
    "    locs = build_locations(N_LOCATIONS)\n",
    "    if LIMIT is not None:\n",
    "        locs = locs[:LIMIT]\n",
    "\n",
    "bbox_map = load_bbox_map(locs)\n",
    "\n",
    "rows = []\n",
    "for loc in tqdm.tqdm(locs, desc=\"Cosmos-Reason2-8B locations\"):\n",
    "    lat, lon = loc.split(\"_\")\n",
    "    try:\n",
    "        raw, data, prompt_text = run_one_location(loc, bbox_map)\n",
    "\n",
    "        if data is None:\n",
    "            rows.append({\n",
    "                \"lat\": float(lat), \"lon\": float(lon), \"lat_lon\": loc,\n",
    "                \"status\": \"parse_fail\", \"raw_output\": raw,\n",
    "                **({\"prompt_text\": prompt_text} if SAVE_PROMPT_IN_CSV else {}),\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        seq = presence_sequence_from_output(data)\n",
    "        inconsistent = has_inconsistent_presence(seq)\n",
    "\n",
    "        row = {\n",
    "            \"lat\": float(lat),\n",
    "            \"lon\": float(lon),\n",
    "            \"lat_lon\": loc,\n",
    "            **({\"prompt_text\": prompt_text} if SAVE_PROMPT_IN_CSV else {}),\n",
    "            \"presence\": bool(data.get(\"presence\", False)),\n",
    "            \"appearance_year\": safe_int(data.get(\"appearance_year\", 0)),\n",
    "            \"appearance_type\": data.get(\"appearance_type\", \"none\"),\n",
    "\n",
    "            \"type_transition_year_before\": safe_int(data.get(\"type_transition_year_before\", 0)),\n",
    "            \"type_transition_year_after\": safe_int(data.get(\"type_transition_year_after\", 0)),\n",
    "            \"type_transition_note\": data.get(\"type_transition_note\", \"\"),\n",
    "\n",
    "            \"shape_transition_year_before\": safe_int(data.get(\"shape_transition_year_before\", 0)),\n",
    "            \"shape_transition_year_after\": safe_int(data.get(\"shape_transition_year_after\", 0)),\n",
    "            \"shape_transition_note\": data.get(\"shape_transition_note\", \"\"),\n",
    "\n",
    "            \"demolished\": bool(data.get(\"demolished\", False)),\n",
    "            \"demolished_year\": safe_int(data.get(\"demolished_year\", 0)),\n",
    "            \"negative_sample\": bool(data.get(\"negative_sample\", False)),\n",
    "\n",
    "            \"confidence\": data.get(\"confidence\", \"unknown\"),\n",
    "            \"inconsistent_presence\": bool(inconsistent),\n",
    "            \"review_priority_score\": int(review_priority(data.get(\"confidence\", \"unknown\"), inconsistent)),\n",
    "\n",
    "            # \"presence_seq\": json.dumps({str(YEARS[i]): bool(seq[i]) for i in range(len(YEARS))}, ensure_ascii=False),\n",
    "            \"monitoring_note_one_line\": data.get(\"monitoring_note_one_line\", \"\"),\n",
    "\n",
    "            \"raw_output\": json.dumps(data, ensure_ascii=False),\n",
    "            \"status\": \"ok\",\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "    except Exception as e:\n",
    "        rows.append({\n",
    "            \"lat\": float(lat), \"lon\": float(lon), \"lat_lon\": loc,\n",
    "            \"status\": \"exception\", \"error\": repr(e), \"raw_output\": \"\",\n",
    "            **({\"prompt_text\": \"\"} if SAVE_PROMPT_IN_CSV else {}),\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values([\"review_priority_score\"], ascending=False)\n",
    "Path(OUT_CSV).parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "print(\"Saved:\", OUT_CSV)\n",
    "print(df[\"status\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a4856a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c58efab2d56485d9153932560fed917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94cbeeec8bf14aec8333a0d209858932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8c489c55cf43f095f878977eb83026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cosmos-Reason2-8B video locations:   0%|          | 0/924 [00:00<?, ?it/s]/opt/anaconda3/envs/rishabh_sat/lib/python3.12/site-packages/transformers/video_processing_utils.py:873: UserWarning: `torchcodec` is not installed and cannot be used to decode the video by default. Falling back to `torchvision`. Note that `torchvision` decoding is deprecated and will be removed in future versions. \n",
      "  warnings.warn(\n",
      "Cosmos-Reason2-8B video locations: 100%|██████████| 924/924 [00:50<00:00, 18.32it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'review_priority_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2147403/664785496.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;34m\"status\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"exception\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"error\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw_output\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"prompt_text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mSAVE_PROMPT_IN_CSV\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"review_priority_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUT_CSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUT_CSV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUT_CSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/rishabh_sat/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   7207\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7208\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7209\u001b[0m             \u001b[0;31m# len(by) == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7211\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7213\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7214\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/rishabh_sat/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1910\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1911\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1912\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1914\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'review_priority_score'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# =========================\n",
    "# GPU + CPU LIMITS (set before torch/transformers)\n",
    "# =========================\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"   # physical GPU 2,3 only\n",
    "N_THREADS = 16\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(N_THREADS)\n",
    "os.environ[\"MKL_NUM_THREADS\"] = str(N_THREADS)\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = str(N_THREADS)\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = str(N_THREADS)\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = str(N_THREADS)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from transformers import Qwen3VLForConditionalGeneration, AutoProcessor\n",
    "import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "torch.set_num_threads(N_THREADS)\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "YEARS = [2014, 2016, 2018, 2020, 2022, 2024]\n",
    "YEARS_STR = \", \".join(str(y) for y in YEARS)\n",
    "\n",
    "BASE_DIR = Path(\"/home/rishabh.mondal/Brick-Kilns-project/ijcai_2025_kilns/temporal-analysis/data\")\n",
    "FOLDER_TPL = \"delhi_airshed_y_{y}_z_17_buf_25m\"\n",
    "BBOX_CSV = Path(\n",
    "    \"/home/rishabh.mondal/Brick-Kilns-project/ijcai_2025_kilns/temporal-analysis/\"\n",
    "    \"qwen3_30b_bbox_pixels_2025.csv\"\n",
    ")\n",
    "\n",
    "# Video cache directory\n",
    "VIDEO_CACHE_DIR = Path(\"/home/rishabh.mondal/Brick-Kilns-project/ijcai_2025_kilns/temporal-analysis/video_cache\")\n",
    "VIDEO_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_ID = \"nvidia/Cosmos-Reason2-8B\"\n",
    "OUT_CSV = \"/home/rishabh.mondal/Brick-Kilns-project/ijcai_2025_kilns/temporal-analysis/cosmos_reason2_8b_kiln_change_results_delhi_video_bbox.csv\"\n",
    "\n",
    "MAX_NEW_TOKENS = 4096  # Cosmos needs more tokens for chain-of-thought\n",
    "N_LOCATIONS = 924\n",
    "LIMIT = None # set e.g. 10 for testing\n",
    "SAVE_PROMPT_IN_CSV = False\n",
    "TARGET_LOC = None # e.g. \"28.604682_77.471200\"\n",
    "\n",
    "# Video settings - 1 fps means model sees each year-frame with equal temporal spacing\n",
    "VIDEO_FPS = 1.0  # 1 frame per second = 1 year per second in video\n",
    "VIDEO_CODEC = \"mp4v\"  # or \"avc1\" for H.264\n",
    "\n",
    "\n",
    "# =========================\n",
    "# PROMPT\n",
    "# =========================\n",
    "PROMPT_TEMPLATE = f\"\"\"\n",
    "You are analyzing multi year satellite image chips of the SAME location across years {YEARS_STR}.\n",
    "The video shows temporal progression with 1 frame per year.\n",
    "Pixel bboxes from labels, format: [x_min, y_min, x_max, y_max].\n",
    "{{BBOX_LINE}}\n",
    "Use these exact boxes for all years. Do not invent boxes.\n",
    "If the list is [[0, 0, 0, 0]], treat as negative (no bbox).\n",
    "Detect brick kiln like structures and track changes over time.\n",
    "\n",
    "Return STRICT JSON only. No markdown. No extra text.\n",
    "\n",
    "Definitions:\n",
    "presence: true if kiln like structure is present in the location in any year, false otherwise\n",
    "kiln_present: whether kiln like structure exists in that year\n",
    "kiln_shape: one of [\"circular_oval\",\"oval_round\",\"rectangular_sharp_edge_corners\",\"none\"]\n",
    "kiln_type: one of [\"FCBK\",\"CFCBK\",\"Zigzag\",\"none\"]\n",
    "\n",
    "Infer:\n",
    "presence: true if any year has kiln_present true, otherwise false\n",
    "appearance_year: first year kiln_present becomes true\n",
    "type transition: (FCBK or CFCBK) -> Zigzag\n",
    "shape transition: circular_oval or oval_round -> rectangular_sharp_edge_corners\n",
    "demolished_year: first year after being present where kiln_present becomes false and stays absent thereafter (best effort)\n",
    "negative_sample: true if kiln_present is false for all years\n",
    "\n",
    "Output JSON schema:\n",
    "{{\n",
    "  \"presence\": <true/false>,\n",
    "  \"appearance_year\": <int or 0>,\n",
    "  \"appearance_type\": \"<kiln_type at appearance or 'none'>\",\n",
    "  \"type_transition_year_before\": <int or 0>,\n",
    "  \"type_transition_year_after\": <int or 0>,\n",
    "  \"type_transition_note\": \"<short>\",\n",
    "  \"shape_transition_year_before\": <int or 0>,\n",
    "  \"shape_transition_year_after\": <int or 0>,\n",
    "  \"shape_transition_note\": \"<short>\",\n",
    "  \"demolished\": <true/false>,\n",
    "  \"demolished_year\": <int or 0>,\n",
    "  \"negative_sample\": <true/false>,\n",
    "  \"monitoring_note_one_line\": \"<one line summary of evolution over years>\",\n",
    "  \"confidence\": \"<low|medium|high>\"\n",
    "}}\n",
    "\n",
    "Be conservative. If unsure set type or shape to \"unknown\". If not present set to \"none\".\n",
    "\"\"\"\n",
    "\n",
    "# =========================\n",
    "# Build year maps\n",
    "# =========================\n",
    "def build_year_maps() -> Dict[int, Dict[str, Path]]:\n",
    "    year_maps: Dict[int, Dict[str, Path]] = {}\n",
    "    for y in YEARS:\n",
    "        folder = BASE_DIR / FOLDER_TPL.format(y=y)\n",
    "        if not folder.exists():\n",
    "            raise FileNotFoundError(f\"Missing folder: {folder}\")\n",
    "\n",
    "        mapping: Dict[str, Path] = {}\n",
    "        for f in folder.glob(\"*.png\"):\n",
    "            # expected: 28.208668_77.420208_2014.png\n",
    "            parts = f.stem.split(\"_\")\n",
    "            if len(parts) >= 3:\n",
    "                key = f\"{parts[0]}_{parts[1]}\"\n",
    "                mapping[key] = f\n",
    "        year_maps[y] = mapping\n",
    "    return year_maps\n",
    "\n",
    "def build_locations(n_locations: int) -> List[str]:\n",
    "    year_maps = build_year_maps()\n",
    "    common = set.intersection(*(set(year_maps[y].keys()) for y in YEARS))\n",
    "    common = sorted(list(common))\n",
    "    if len(common) < n_locations:\n",
    "        raise ValueError(f\"Need {n_locations} common locations, found {len(common)}\")\n",
    "    return common[:n_locations]\n",
    "\n",
    "def load_images_for_loc(loc: str) -> List[Image.Image]:\n",
    "    year_maps = build_year_maps()\n",
    "    imgs: List[Image.Image] = []\n",
    "    for y in YEARS:\n",
    "        p = year_maps[y][loc]\n",
    "        imgs.append(Image.open(p).convert(\"RGB\"))\n",
    "    return imgs\n",
    "\n",
    "def create_video_from_images(loc: str, imgs: List[Image.Image]) -> Path:\n",
    "    \"\"\"Create a video file from image sequence, with caching.\"\"\"\n",
    "    # Check cache first\n",
    "    video_path = VIDEO_CACHE_DIR / f\"{loc}.mp4\"\n",
    "    if video_path.exists():\n",
    "        return video_path\n",
    "\n",
    "    # Get image dimensions from first image\n",
    "    img_array = np.array(imgs[0])\n",
    "    height, width, _ = img_array.shape\n",
    "\n",
    "    # Create video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*VIDEO_CODEC)\n",
    "    video_writer = cv2.VideoWriter(\n",
    "        str(video_path),\n",
    "        fourcc,\n",
    "        VIDEO_FPS,\n",
    "        (width, height)\n",
    "    )\n",
    "\n",
    "    # Write frames\n",
    "    for img in imgs:\n",
    "        # Convert PIL to numpy array and BGR (OpenCV format)\n",
    "        frame = np.array(img)\n",
    "        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        video_writer.write(frame_bgr)\n",
    "\n",
    "    video_writer.release()\n",
    "    return video_path\n",
    "\n",
    "def load_bbox_map(locs: List[str]) -> Dict[str, List[List[float]]]:\n",
    "    \"\"\"Load bounding boxes directly from existing CSV (already in pixel coordinates).\"\"\"\n",
    "    if not BBOX_CSV.exists():\n",
    "        raise FileNotFoundError(f\"Bbox CSV not found: {BBOX_CSV}\")\n",
    "\n",
    "    df = pd.read_csv(BBOX_CSV)\n",
    "    if \"lat_lon\" not in df.columns or \"bbox_json\" not in df.columns:\n",
    "        raise ValueError(f\"Bbox CSV missing required columns: {BBOX_CSV}\")\n",
    "\n",
    "    bbox_map: Dict[str, List[List[float]]] = {}\n",
    "    for _, row in df.iterrows():\n",
    "        loc = str(row[\"lat_lon\"])\n",
    "        raw = row.get(\"bbox_json\", \"[]\")\n",
    "        try:\n",
    "            parsed = json.loads(raw) if isinstance(raw, str) else raw\n",
    "        except Exception:\n",
    "            parsed = [[0.0, 0.0, 0.0, 0.0]]\n",
    "        if not parsed:\n",
    "            parsed = [[0.0, 0.0, 0.0, 0.0]]\n",
    "        bbox_map[loc] = parsed\n",
    "\n",
    "    # Check if all requested locations have bboxes\n",
    "    missing = set(locs) - set(bbox_map.keys())\n",
    "    if missing:\n",
    "        print(f\"Warning: {len(missing)} locations missing from bbox CSV\")\n",
    "        # Add empty bboxes for missing locations\n",
    "        for loc in missing:\n",
    "            bbox_map[loc] = [[0.0, 0.0, 0.0, 0.0]]\n",
    "\n",
    "    return bbox_map\n",
    "\n",
    "def format_bboxes_for_prompt(loc: str, bbox_map: Dict[str, List[List[float]]]) -> str:\n",
    "    bboxes = bbox_map.get(loc, [[0.0, 0.0, 0.0, 0.0]])\n",
    "    bbox_strs = []\n",
    "    for bb in bboxes:\n",
    "        if len(bb) != 4:\n",
    "            continue\n",
    "        bbox_strs.append(\"[\" + \", \".join(f\"{v:.2f}\" for v in bb) + \"]\")\n",
    "    if not bbox_strs:\n",
    "        bbox_strs = [\"[0.00, 0.00, 0.00, 0.00]\"]\n",
    "    return \"FOCUS ONLY on the region defined by bounding box: [\" + \", \".join(bbox_strs) + \"]\"\n",
    "\n",
    "# =========================\n",
    "# JSON parse (robust)\n",
    "# =========================\n",
    "def extract_json(text: str):\n",
    "    text = (text or \"\").strip()\n",
    "    # Cosmos may output <think>...</think> reasoning, extract JSON after it\n",
    "    think_match = re.search(r\"</think>\\s*(.+)\", text, flags=re.DOTALL)\n",
    "    if think_match:\n",
    "        text = think_match.group(1).strip()\n",
    "\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        pass\n",
    "    m = re.search(r\"\\{.*\\}\", text, flags=re.DOTALL)\n",
    "    if not m:\n",
    "        return None\n",
    "    cand = m.group(0)\n",
    "    try:\n",
    "        return json.loads(cand)\n",
    "    except Exception:\n",
    "        cand2 = re.sub(r\"\\s+\", \" \", cand).strip()\n",
    "        try:\n",
    "            return json.loads(cand2)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "# =========================\n",
    "# Consistency flags (same logic)\n",
    "# =========================\n",
    "def _as_bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v is None:\n",
    "        return False\n",
    "    if isinstance(v, (int, float)):\n",
    "        return bool(v)\n",
    "    s = str(v).strip().lower()\n",
    "    return s in {\"true\", \"1\", \"yes\", \"present\"}\n",
    "\n",
    "def presence_sequence_from_output(data):\n",
    "    roi = data.get(\"roi_state_by_year\", {}) or {}\n",
    "    seq = []\n",
    "    for y in YEARS:\n",
    "        st = roi.get(str(y), {}) or {}\n",
    "        seq.append(_as_bool(st.get(\"kiln_present\", False)))\n",
    "    return seq\n",
    "\n",
    "def has_inconsistent_presence(seq):\n",
    "    seen_present = False\n",
    "    seen_absent_after_present = False\n",
    "    for v in seq:\n",
    "        if v and not seen_present:\n",
    "            seen_present = True\n",
    "        elif (not v) and seen_present:\n",
    "            seen_absent_after_present = True\n",
    "        elif v and seen_absent_after_present:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def confidence_to_score(conf):\n",
    "    c = str(conf).strip().lower()\n",
    "    if c == \"high\": return 0\n",
    "    if c == \"medium\": return 1\n",
    "    if c == \"low\": return 2\n",
    "    return 1\n",
    "\n",
    "def review_priority(confidence, inconsistent):\n",
    "    return confidence_to_score(confidence) + (2 if inconsistent else 0)\n",
    "\n",
    "def safe_int(x):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    if pd.isna(x):\n",
    "        return 0\n",
    "    return int(x)\n",
    "\n",
    "# =========================\n",
    "# Model load\n",
    "# =========================\n",
    "if torch.cuda.device_count() < 1:\n",
    "    raise RuntimeError(\"No visible CUDA GPUs. Check CUDA_VISIBLE_DEVICES.\")\n",
    "\n",
    "model = Qwen3VLForConditionalGeneration.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"sdpa\",\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(MODEL_ID)\n",
    "\n",
    "# =========================\n",
    "# Run one location with video\n",
    "# =========================\n",
    "def run_one_location(loc: str, bbox_map: Dict[str, List[List[float]]]):\n",
    "    imgs = load_images_for_loc(loc)\n",
    "    video_path = create_video_from_images(loc, imgs)\n",
    "\n",
    "    bbox_text = format_bboxes_for_prompt(loc, bbox_map)\n",
    "    prompt = PROMPT_TEMPLATE.replace(\"{BBOX_LINE}\", bbox_text)\n",
    "\n",
    "    # Use video format for Cosmos temporal reasoning\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"video\",\n",
    "                    \"video\": f\"file://{video_path.resolve()}\",\n",
    "                    \"fps\": VIDEO_FPS,\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    inputs = processor.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_dict=True,\n",
    "        return_tensors=\"pt\",\n",
    "        fps=VIDEO_FPS,\n",
    "    )\n",
    "    inputs = inputs.to(model.device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        out_ids = model.generate(**inputs, max_new_tokens=MAX_NEW_TOKENS)\n",
    "\n",
    "    trimmed = [o[len(i):] for i, o in zip(inputs[\"input_ids\"], out_ids)]\n",
    "    text = processor.batch_decode(trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "    data = extract_json(text)\n",
    "    return text, data, prompt\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "if TARGET_LOC is not None:\n",
    "    year_maps = build_year_maps()\n",
    "    common = set.intersection(*(set(year_maps[y].keys()) for y in YEARS))\n",
    "    if TARGET_LOC not in common:\n",
    "        raise ValueError(f\"TARGET_LOC not found in common locations: {TARGET_LOC}\")\n",
    "    locs = [TARGET_LOC]\n",
    "else:\n",
    "    locs = build_locations(N_LOCATIONS)\n",
    "    if LIMIT is not None:\n",
    "        locs = locs[:LIMIT]\n",
    "\n",
    "bbox_map = load_bbox_map(locs)\n",
    "\n",
    "rows = []\n",
    "for loc in tqdm.tqdm(locs, desc=\"Cosmos-Reason2-8B video locations\"):\n",
    "    lat, lon = loc.split(\"_\")\n",
    "    try:\n",
    "        raw, data, prompt_text = run_one_location(loc, bbox_map)\n",
    "\n",
    "        if data is None:\n",
    "            rows.append({\n",
    "                \"lat\": float(lat), \"lon\": float(lon), \"lat_lon\": loc,\n",
    "                \"status\": \"parse_fail\", \"raw_output\": raw,\n",
    "                **({\"prompt_text\": prompt_text} if SAVE_PROMPT_IN_CSV else {}),\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        seq = presence_sequence_from_output(data)\n",
    "        inconsistent = has_inconsistent_presence(seq)\n",
    "\n",
    "        row = {\n",
    "            \"lat\": float(lat),\n",
    "            \"lon\": float(lon),\n",
    "            \"lat_lon\": loc,\n",
    "            **({\"prompt_text\": prompt_text} if SAVE_PROMPT_IN_CSV else {}),\n",
    "            \"presence\": bool(data.get(\"presence\", False)),\n",
    "            \"appearance_year\": safe_int(data.get(\"appearance_year\", 0)),\n",
    "            \"appearance_type\": data.get(\"appearance_type\", \"none\"),\n",
    "\n",
    "            \"type_transition_year_before\": safe_int(data.get(\"type_transition_year_before\", 0)),\n",
    "            \"type_transition_year_after\": safe_int(data.get(\"type_transition_year_after\", 0)),\n",
    "            \"type_transition_note\": data.get(\"type_transition_note\", \"\"),\n",
    "\n",
    "            \"shape_transition_year_before\": safe_int(data.get(\"shape_transition_year_before\", 0)),\n",
    "            \"shape_transition_year_after\": safe_int(data.get(\"shape_transition_year_after\", 0)),\n",
    "            \"shape_transition_note\": data.get(\"shape_transition_note\", \"\"),\n",
    "\n",
    "            \"demolished\": bool(data.get(\"demolished\", False)),\n",
    "            \"demolished_year\": safe_int(data.get(\"demolished_year\", 0)),\n",
    "            \"negative_sample\": bool(data.get(\"negative_sample\", False)),\n",
    "\n",
    "            \"confidence\": data.get(\"confidence\", \"unknown\"),\n",
    "            \"inconsistent_presence\": bool(inconsistent),\n",
    "            \"review_priority_score\": int(review_priority(data.get(\"confidence\", \"unknown\"), inconsistent)),\n",
    "\n",
    "            # \"presence_seq\": json.dumps({str(YEARS[i]): bool(seq[i]) for i in range(len(YEARS))}, ensure_ascii=False),\n",
    "            \"monitoring_note_one_line\": data.get(\"monitoring_note_one_line\", \"\"),\n",
    "\n",
    "            \"raw_output\": json.dumps(data, ensure_ascii=False),\n",
    "            \"status\": \"ok\",\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "    except Exception as e:\n",
    "        rows.append({\n",
    "            \"lat\": float(lat), \"lon\": float(lon), \"lat_lon\": loc,\n",
    "            \"status\": \"exception\", \"error\": repr(e), \"raw_output\": \"\",\n",
    "            **({\"prompt_text\": \"\"} if SAVE_PROMPT_IN_CSV else {}),\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values([\"review_priority_score\"], ascending=False)\n",
    "Path(OUT_CSV).parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "print(\"Saved:\", OUT_CSV)\n",
    "print(df[\"status\"].value_counts(dropna=False))\n",
    "print(f\"\\nVideo cache directory: {VIDEO_CACHE_DIR}\")\n",
    "print(f\"Cached videos can be reused for future runs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a355c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rishabh_sat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
