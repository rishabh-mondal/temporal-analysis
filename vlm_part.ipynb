{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690968d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from transformers import Qwen3VLForConditionalGeneration, AutoProcessor\n",
    "import tqdm\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "model_id = \"Qwen/Qwen3-VL-8B-Instruct\"\n",
    "\n",
    "panels_dir = Path(\"/home/rishabh.mondal/Brick-Kilns-project/ijcai_2025_kilns/temporal-analysis/data/panels_with_polygon\")\n",
    "out_csv = \"data/vlm_kiln_appearance_results.csv\"\n",
    "\n",
    "years = [2014, 2016, 2018, 2020, 2022, 2024, 2025]\n",
    "max_new_tokens = 1024\n",
    "\n",
    "# if you want to limit for testing, set e.g. 20, else None\n",
    "limit = None\n",
    "\n",
    "# =========================\n",
    "# MODEL LOAD\n",
    "# =========================\n",
    "model = Qwen3VLForConditionalGeneration.from_pretrained(\n",
    "    model_id, dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# =========================\n",
    "# PROMPT TEMPLATE\n",
    "# =========================\n",
    "PROMPT = f\"\"\"\n",
    "You are analyzing a temporal panel of satellite images of the SAME location.\n",
    "The panel contains {len(years)} sub-images in ONE ROW (left to right) for years:\n",
    "{years}.\n",
    "\n",
    "Focus ONLY on the kiln area inside/along the red boundary (treat it as the ROI).\n",
    "Ignore surroundings outside the red boundary.\n",
    "\n",
    "Task:\n",
    "1) Compare each year with the previous year within the ROI.\n",
    "2) Identify the earliest year where a kiln structure (oval/rectangular; red/brown/gray kiln-like morphology) first appears in the ROI.\n",
    "3) If no kiln appears in any year in the ROI, return \"no kiln present\".\n",
    "\n",
    "Output STRICTLY as JSON:\n",
    "{{\n",
    "  \"appearance_year\": <year or \"no kiln present\">,\n",
    "  \"roi_state_by_year\": {{\n",
    "     \"2014\": \"<present|absent|unclear>\",\n",
    "     \"2016\": \"<present|absent|unclear>\",\n",
    "     \"2018\": \"<present|absent|unclear>\",\n",
    "     \"2020\": \"<present|absent|unclear>\",\n",
    "     \"2022\": \"<present|absent|unclear>\",\n",
    "     \"2024\": \"<present|absent|unclear>\",\n",
    "     \"2025\": \"<present|absent|unclear>\"\n",
    "  }},\n",
    "  \"confidence\": \"<high|medium|low>\"\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "Use only visual evidence from the ROI.\n",
    "If uncertain, use \"unclear\" and lower confidence.\n",
    "\"\"\"\n",
    "\n",
    "# =========================\n",
    "# JSON EXTRACTION (robust)\n",
    "# =========================\n",
    "def extract_json(text: str):\n",
    "    text = text.strip()\n",
    "\n",
    "    # try direct\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # try first {...} block\n",
    "    m = re.search(r\"\\{.*\\}\", text, flags=re.DOTALL)\n",
    "    if m:\n",
    "        cand = m.group(0)\n",
    "        try:\n",
    "            return json.loads(cand)\n",
    "        except Exception:\n",
    "            # minor cleanup attempts\n",
    "            cand2 = cand.replace(\"\\n\", \" \").strip()\n",
    "            try:\n",
    "                return json.loads(cand2)\n",
    "            except Exception:\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "# =========================\n",
    "# RUN ONE IMAGE\n",
    "# =========================\n",
    "def run_one(panel_path: Path):\n",
    "    img = Image.open(panel_path).convert(\"RGB\")\n",
    "\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"image\": img},\n",
    "            {\"type\": \"text\", \"text\": PROMPT},\n",
    "        ],\n",
    "    }]\n",
    "\n",
    "    inputs = processor.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_dict=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        generated_ids = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "\n",
    "    trimmed = [out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs[\"input_ids\"], generated_ids)]\n",
    "    out_text = processor.batch_decode(\n",
    "        trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )[0]\n",
    "\n",
    "    data = extract_json(out_text)\n",
    "    return out_text, data\n",
    "\n",
    "# =========================\n",
    "# MAIN LOOP\n",
    "# =========================\n",
    "panel_files = sorted(panels_dir.glob(\"*.png\"))\n",
    "\n",
    "if limit is not None:\n",
    "    panel_files = panel_files[:limit]\n",
    "\n",
    "rows = []\n",
    "for p in tqdm.tqdm(panel_files):\n",
    "    lat_lon = p.stem  # filename without .png\n",
    "\n",
    "    try:\n",
    "        raw, data = run_one(p)\n",
    "\n",
    "        if data is None:\n",
    "            rows.append({\n",
    "                \"lat_lon\": lat_lon,\n",
    "                \"panel_path\": str(p),\n",
    "                \"appearance_year\": \"\",\n",
    "                \"confidence\": \"\",\n",
    "                \"status\": \"parse_fail\",\n",
    "                \"raw_output\": raw\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        appearance_year = data.get(\"appearance_year\", \"\")\n",
    "        confidence = data.get(\"confidence\", \"\")\n",
    "\n",
    "        # flatten roi_state_by_year\n",
    "        roi = data.get(\"roi_state_by_year\", {}) or {}\n",
    "        row = {\n",
    "            \"lat_lon\": lat_lon,\n",
    "            \"panel_path\": str(p),\n",
    "            \"appearance_year\": appearance_year,\n",
    "            \"confidence\": confidence,\n",
    "            \"status\": \"ok\",\n",
    "            \"raw_output\": raw\n",
    "        }\n",
    "        for y in years:\n",
    "            row[f\"roi_{y}\"] = roi.get(str(y), \"\")\n",
    "\n",
    "        # keep change notes as json string\n",
    "        row[\"change_notes\"] = json.dumps(data.get(\"change_notes\", []), ensure_ascii=False)\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    except Exception as e:\n",
    "        rows.append({\n",
    "            \"lat_lon\": lat_lon,\n",
    "            \"panel_path\": str(p),\n",
    "            \"appearance_year\": \"\",\n",
    "            \"confidence\": \"\",\n",
    "            \"status\": \"exception\",\n",
    "            \"error\": repr(e),\n",
    "            \"raw_output\": \"\"\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(\"Saved:\", out_csv)\n",
    "print(df[\"status\"].value_counts(dropna=False))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
